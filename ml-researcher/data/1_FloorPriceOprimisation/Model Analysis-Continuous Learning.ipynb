{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis: Floor Price Optimisation\n",
    "\n",
    "## Continuous Learning Experiment\n",
    "- Author: Reshad Dernjani\n",
    "- This will run the analysis for two models on test data (next day hour 10, 8% unoptimized traffic), where the DSP bids are reduced by 90%\n",
    "  * A model trained with data of the previous day (hour 00-23, 8% unoptimized traffic)\n",
    "  * is compared to a model using in addition warm start training to be updated with reduced DSP bids (next day hour 9, 8% unoptimized traffic)\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "inventory_id, request_type, ex_floor_price, ex_bid_price, state_code, country_code, city_code, device_os, device_os_version, device_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import tensorflow_transform as tft\n",
    "    import apache_beam as beam\n",
    "    import tensorflow_model_analysis as tfma\n",
    "except ImportError:\n",
    "    # This will take a minute, ignore the warnings.\n",
    "    !pip install -q tensorflow-transform\n",
    "    !pip install -q apache_beam\n",
    "    !pip install -q tensorflow-model-analysis\n",
    "    import tensorflow_transform as tft\n",
    "    import apache_beam as beam\n",
    "    import tensorflow_model_analysis as tfma  \n",
    "    \n",
    "import tensorflow as tf\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "\n",
    "from tensorflow_transform.saved import saved_transform_io\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'inventory_id',\n",
    "    'request_type',\n",
    "    'state_code',\n",
    "    'country_code',\n",
    "    'city_code',\n",
    "    'device_os',\n",
    "    'device_os_version',\n",
    "    'hour_of_day',\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURE_KEYS = [\n",
    "    'ex_floor_price',\n",
    "]\n",
    "\n",
    "OPTIONAL_NUMERIC_FEATURE_KEYS = [ \n",
    "    # actually we handled optionals on the data query (at least for research)\n",
    "]\n",
    "\n",
    "LABEL_KEY = 'ex_bid_price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our features and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FEATURE_SPEC = dict(\n",
    "    [(name, tf.FixedLenFeature([], tf.string))\n",
    "     for name in CATEGORICAL_FEATURE_KEYS] +\n",
    "    [(name, tf.FixedLenFeature([], tf.float32))\n",
    "     for name in NUMERIC_FEATURE_KEYS] +\n",
    "    [(name, tf.VarLenFeature(tf.float32))\n",
    "     for name in OPTIONAL_NUMERIC_FEATURE_KEYS] +\n",
    "    [(LABEL_KEY, tf.FixedLenFeature([], tf.float32))]\n",
    ")\n",
    "\n",
    "RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\n",
    "    dataset_schema.from_feature_spec(RAW_DATA_FEATURE_SPEC)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names of temp files\n",
    "TRANSFORMED_TRAIN_DATA_FILEBASE = 'train_transformed'\n",
    "TRANSFORMED_TEST_DATA_FILEBASE = 'test_transformed'\n",
    "EXPORTED_MODEL_DIR = 'exported_model_dir'\n",
    "EXPORTED_EVAL_MODEL_DIR = 'eval_dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_results(predictions, labels):\n",
    "    # Sort values keeping predictions and lables pairs together\n",
    "    tmp_pairs = []\n",
    "    for x in range(len(labels)):\n",
    "        tmp_pairs.append([labels[x],predictions[x]])\n",
    "    def getKey(item):\n",
    "        return item[0]\n",
    "    sorted_predictions = []\n",
    "    sorted_labels = []\n",
    "    for pair in sorted(tmp_pairs, key=getKey):\n",
    "        sorted_labels.append(pair[0])\n",
    "        sorted_predictions.append(pair[1])\n",
    "    \n",
    "    return sorted_predictions, sorted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_results(iterations, path):\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=path)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    floor_prices = []\n",
    "    i = 0\n",
    "    for string_record in record_iterator:\n",
    "        #prediction = predict_fn({'inputs': [string_record]})\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "        labels.append(example.features.feature['ex_bid_price'].float_list.value[0])\n",
    "        floor_prices.append(example.features.feature['ex_floor_price'].float_list.value[0])\n",
    "        pred = predict_fn({'examples': [example.SerializeToString()]})\n",
    "        predictions.append(pred['predictions'][0])\n",
    "        i+=1\n",
    "        if i==iterations:\n",
    "            break\n",
    "    return predictions, labels, floor_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_revenue(new_floor_prices, dsp_bids, old_floor_prices):\n",
    "    # The bid price predictions are used as the new floor price. The labels are the original bids \n",
    "    abs_rev_new = 1e-10\n",
    "    abs_rev_old = 1e-10\n",
    "    over_the_bid_counter = 0\n",
    "    below_zero_counter = 0\n",
    "    iterations = len(raw_pred)\n",
    "    for x in range(iterations):\n",
    "        abs_rev_new +=  new_floor_prices[x] if new_floor_prices[x] > 0 and new_floor_prices[x] < dsp_bids[x] else old_floor_prices[x]\n",
    "        abs_rev_old +=  old_floor_prices[x] if old_floor_prices[x] < dsp_bids[x] else 0.\n",
    "        over_the_bid_counter += 1 if new_floor_prices[x] > dsp_bids[x] else 0\n",
    "        below_zero_counter += 1 if new_floor_prices[x] < 0 else 0\n",
    "    over_the_bid_pct = (over_the_bid_counter / iterations) * 100\n",
    "    below_zero_pct = (below_zero_counter / iterations) * 100\n",
    "    return abs_rev_new, abs_rev_old, over_the_bid_pct, below_zero_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_speed(iterations, path):\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=path)\n",
    "    i = 0\n",
    "    start = time.time()\n",
    "    for string_record in record_iterator:\n",
    "        pred = predict_fn({'examples': [string_record]})\n",
    "        i+=1\n",
    "        if i==iterations:\n",
    "            break\n",
    "    elapsed_sec = time.time() - start\n",
    "    millisec_per_req = (elapsed_sec * 1000) / iterations\n",
    "    print('\\n\\nPrediction for {} requests took {:.2f} seconds. Resulting in {:.2f} milliseconds per prediction.\\n\\n'\n",
    "          .format(iterations, elapsed_sec, millisec_per_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_instances(tf_records_filenames):\n",
    "    counter = 0\n",
    "    for fn in tf_records_filenames:\n",
    "        for record in tf.python_io.tf_record_iterator(fn):\n",
    "            counter += 1 \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import decimal\n",
    "import matplotlib.pyplot as plt\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "total_rev_new = 0.\n",
    "total_rev_old = 0.\n",
    "total_potential_revenue = 0.\n",
    "total_num_of_predictions = 0\n",
    "total_over_the_bid_count = 0\n",
    "total_below_zero_count = 0\n",
    "\n",
    "# Base directory of the exported models.\n",
    "directory = 'tmp'\n",
    "# List of models to analyse\n",
    "dsp_list = ['47_warmstarting', '47']\n",
    "\n",
    "for dsp in dsp_list:\n",
    "    print(\"\\n\\n\\nAnalysis for dsp: {}\\n\".format(dsp))\n",
    "    \n",
    "    transformed_dir = '/notebooks/transformed/' + '47_warmstarting'\n",
    "    model_path = tf.gfile.Glob('/notebooks/tmp/' + dsp +'/exported_model_dir/1*')[0]\n",
    "    tf_records_filenames = tf.gfile.Glob(transformed_dir + '/test_transformed*')\n",
    "    \n",
    "    for test_path in tf_records_filenames:\n",
    "        print(test_path)\n",
    "        instances_count = count_instances([test_path])\n",
    "        num_of_predictions = 1000 if instances_count > 1000 else instances_count\n",
    "        total_num_of_predictions += num_of_predictions\n",
    "    \n",
    "        # Load model\n",
    "        predict_fn = tf.contrib.predictor.from_saved_model(model_path)\n",
    "\n",
    "        # Collect results\n",
    "        raw_pred, raw_labels, old_floor_prices = get_prediction_results(num_of_predictions, test_path)\n",
    "        predictions, labels = sort_results(raw_pred, raw_labels)\n",
    "\n",
    "        # Calculate uplift and revenue\n",
    "        abs_rev_new, abs_rev_old, over_the_bid_pct, below_zero_pct = calc_revenue(raw_pred, raw_labels, old_floor_prices)\n",
    "        uplift = (abs_rev_new / abs_rev_old) - 1\n",
    "        abs_potential_revenue = sum(raw_labels)\n",
    "        print(\"New revenue: {:.2f}, old revenue: {:.2f}, uplift: {:.2f}%, potential revenue: {:.2f}.\"\n",
    "            .format(abs_rev_new, abs_rev_old, uplift*100, abs_potential_revenue))\n",
    "        print(\"{:.2f}% of the predictions were higher than the winning bid!\".format(over_the_bid_pct))\n",
    "        print(\"{:.2f}% of the predictions were below zero!\".format(below_zero_pct))\n",
    "        \n",
    "        # Collect overall summary\n",
    "        total_rev_new += abs_rev_new\n",
    "        total_rev_old += abs_rev_old\n",
    "        total_potential_revenue += abs_potential_revenue\n",
    "        total_over_the_bid_count = num_of_predictions * (over_the_bid_pct/100)\n",
    "        total_below_zero_count = num_of_predictions * (below_zero_pct/100)\n",
    "\n",
    "        # Calculate prediction speed\n",
    "        get_prediction_speed(num_of_predictions, test_path)\n",
    "\n",
    "        # Plot: Prediction vs Label\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.plot(predictions, label='Predictions')\n",
    "        plt.plot(labels, label='Labels')\n",
    "        plt.legend()\n",
    "        plt.ylim(-2.0,10.0)\n",
    "        plt.yticks(np.arange(-2, 11, 1.0))\n",
    "        plt.grid(True, which='both')\n",
    "        plt.axhline(y=0, color='k')\n",
    "        plt.axvline(x=0, color='k')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Bid Price')\n",
    "        plt.title('Predictions vs Labels Curve',fontsize=16)\n",
    "        plt.show()\n",
    " \n",
    "        old_floor, new_floor = sort_results(old_floor_prices, raw_pred)\n",
    "\n",
    "        # Plot: Predictions vs Floor Prices\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.plot(new_floor, label='Predictions')\n",
    "        plt.plot(old_floor, label='Floor Price')\n",
    "        plt.legend()\n",
    "        plt.ylim(-2.0,10.0)\n",
    "        plt.yticks(np.arange(-2, 11, 1.0))\n",
    "        plt.grid(True, which='both')\n",
    "        plt.axhline(y=0, color='k')\n",
    "        plt.axvline(x=0, color='k')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Price')\n",
    "        plt.title('Predictions vs Floor Prices',fontsize=16)\n",
    "        plt.show()\n",
    "    \n",
    "        # Distribution plot\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.hist(\n",
    "            [raw_pred, raw_labels],\n",
    "            np.arange(-1.5, 10.5, 0.5),\n",
    "            label=['Distribution of predictions', 'Distribution of labels']\n",
    "        )\n",
    "        plt.ylabel('Bid Count')\n",
    "        plt.xlabel('Bid Price Categories')\n",
    "        plt.xlim(-1.5,10.0)\n",
    "        plt.xticks(np.arange(-1.5, 10.5, 0.5))\n",
    "        plt.legend()\n",
    "        plt.title('Distribution Plot',fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot: Scatterplot\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.scatter(labels, predictions, c='red', alpha=0.5)\n",
    "        plt.plot([-2, 10], [-2, 10], ls=\"--\", c=\"black\")\n",
    "        plt.ylim(-2.0,10.0)\n",
    "        plt.xlim(-2.0,10.0)\n",
    "        plt.yticks(np.arange(-2, 11, 1.0))\n",
    "        plt.xticks(np.arange(-2, 11, 1.0))\n",
    "        plt.ylabel(\"Predicted Bid Price\")\n",
    "        plt.xlabel(\"Label Bid Price\")\n",
    "        plt.title('Predictions vs Labels',fontsize=16)\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n\\nOverall analysis\")\n",
    "total_uplift = (total_rev_new / total_rev_old) - 1\n",
    "total_over_the_bid_pct = (total_over_the_bid_count  / total_num_of_predictions) * 100\n",
    "total_below_zero_pct = (total_below_zero_count / total_num_of_predictions) * 100\n",
    "print(\"New revenue: {:.2f}, old revenue: {:.2f}, uplift: {:.2f}%, potential revenue: {:.2f}.\"\n",
    "      .format(total_rev_new, total_rev_old, total_uplift*100, total_potential_revenue))\n",
    "print(\"{:.2f}% of the predictions were higher than the winning bid!\".format(total_over_the_bid_pct))\n",
    "print(\"{:.2f}% of the predictions were below zero!\".format(total_below_zero_pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def serialize_example(inventory_id, request_type, ex_floor_price,\n",
    "                      state_code, country_code, city_code, device_os, device_os_version, hour_of_day):\n",
    "  \n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible data type.\n",
    "    feature = {\n",
    "        'inventory_id': _bytes_feature(inventory_id),\n",
    "        'request_type': _bytes_feature(request_type),\n",
    "        'ex_floor_price': _float_feature(ex_floor_price),\n",
    "        'state_code': _bytes_feature(state_code),\n",
    "        'country_code': _bytes_feature(country_code),\n",
    "        'city_code': _bytes_feature(city_code),\n",
    "        'device_os': _bytes_feature(device_os),\n",
    "        'device_os_version': _bytes_feature(device_os_version),\n",
    "        'hour_of_day': _bytes_feature(hour_of_day),\n",
    "    }\n",
    "  \n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for custom predictions with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = tf.gfile.Glob('/notebooks/tmp/47/exported_model_dir/*')[0]\n",
    "#predict_fn = tf.contrib.predictor.from_saved_model(model_path)\n",
    "\n",
    "#example = serialize_example(\"249621\", \"banner\", 1.6590000000000014, \"TEXAS_ST_US\",\n",
    "#                            \"US\", \"DALLAS_TX_US\", \"Android\", \"8.1\", \"02\")\n",
    "\n",
    "#prediction = predict_fn({'examples': [example]})\n",
    "#prediction = prediction['predictions'][0]\n",
    "\n",
    "#print('Prediction: {}'.format(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
